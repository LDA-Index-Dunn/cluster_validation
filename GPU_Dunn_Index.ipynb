{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the CUDA parallel code for calculating the Dunn index of Clustering output."
      ],
      "metadata": {
        "id": "RN7a7OUSvuXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the CPU available and the gcc version\n",
        "!lscpu | grep CPU\n",
        "!g++ -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sXKjK30vr3v",
        "outputId": "ff70ad78-369a-47b3-dee2-74927454e20b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU op-mode(s):                  32-bit, 64-bit\n",
            "CPU(s):                          2\n",
            "On-line CPU(s) list:             0,1\n",
            "CPU family:                      6\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "CPU MHz:                         2199.998\n",
            "NUMA node0 CPU(s):               0,1\n",
            "Using built-in specs.\n",
            "COLLECT_GCC=g++\n",
            "COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper\n",
            "OFFLOAD_TARGET_NAMES=nvptx-none:hsa\n",
            "OFFLOAD_TARGET_DEFAULT=1\n",
            "Target: x86_64-linux-gnu\n",
            "Configured with: ../src/configure -v --with-pkgversion='Ubuntu 9.4.0-1ubuntu1~20.04.1' --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none=/build/gcc-9-Av3uEd/gcc-9-9.4.0/debian/tmp-nvptx/usr,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\n",
            "Thread model: posix\n",
            "gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the test file used. ItÂ´s da dataset with 10 instances (10), each with\n",
        "# 2 features (f2), forming 2 clusters (k2). The first line has the #clusters and\n",
        "# the #features. The second line has the size of each cluster in order (6 and 4)\n",
        "# the following lines have the instances (data points), one  per file.\n",
        "%%writefile test_k2_f2_10.dat\n",
        "2 2\n",
        "6 4\n",
        "1.0 1.0\n",
        "1.0 3.0\n",
        "2.0 3.0\n",
        "3.0 -1.0\n",
        "3.0 6.0\n",
        "4.0 -4.0\n",
        "-2.0 -4.0\n",
        "-2.0 -2.0\n",
        "-3.0 2.0\n",
        "-4.0 -4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9YIsmzHuMUO",
        "outputId": "9811777a-a272-4c5d-9610-3cd24a4ab7ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_k2_f2_10.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a picture of the test clustering\n",
        "# import image module\n",
        "from IPython.display import Image\n",
        "# get the image\n",
        "Image(url=\"https://drive.google.com/uc?id=1bNVbRFWahzk1EK_rQ8JiZ_MwsGM7ekkT\", width=800, height=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "W-G76QYJ9qMG",
        "outputId": "669f7371-4f3c-4303-c824-1d321c56dcdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://drive.google.com/uc?id=1bNVbRFWahzk1EK_rQ8JiZ_MwsGM7ekkT\" width=\"800\" height=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxE5QtfR8Jl0",
        "outputId": "c05848f5-5bd1-4339-de71-a002a0b16d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 23 22:52:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "#Check the GPU available and the nvcc version\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plBFsjBj9JFN",
        "outputId": "7be062e4-93c6-4403-8bc4-ec8b4a5a6126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-v8l8h5i4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-v8l8h5i4\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=0ece308310b668360924a306b97f371c75ebd101eac2243deca1f0f1270bf5d6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_vfrd9d9/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "# Install nvcc4jupter to easily work with CUDA file and install the nvcc plugin\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ5IC2pnPKXR",
        "outputId": "80e989c7-3912-4222-ab78-af64f4e74493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 + 4 is 7\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# This is a simple CUDA program for testing purpose\n",
        "%%cu\n",
        "#include <stdio.h>\n",
        "__global__ void add(int a, int b, int *c)\n",
        "{ *c = a + b;}\n",
        "int main() {\n",
        "int a,b,c;\n",
        "int *dev_c;\n",
        "a=3; b=4;\n",
        "cudaMalloc((void**)&dev_c, sizeof(int));\n",
        "add<<<1,1>>>(a,b,dev_c);\n",
        "cudaMemcpy(&c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "printf(\"%d + %d is %d\\n\", a, b, c);\n",
        "cudaFree(dev_c);\n",
        "return 0;}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l1lGQWKuA6Bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ea3645-2371-45c6-8d89-fbc6c27002b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Centroid Global: 0.30 0.00 \n",
            "Min intercluster 3.04\n",
            "Min1 intercluster 2.43\n",
            "Max intracluster 10.05\n",
            "The Dunn index: 0.3024\n",
            "The Dunn index1: 0.2419\n",
            "Time taken: 0.262000 milissegundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "// This is the CUDA program for Dunn index calculation\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <float.h>\n",
        "#include <math.h>\n",
        "\n",
        "// Test_k2_f2_10, Iris_k3_f4_150 - Digits_k10_f64_1797 - Electricity_k2_f8_45311\n",
        "// MAX_POINTS 2048 (others) or 65536 (Electric) or 524288 (500K), 3145728, 14680064\n",
        "// NF 2 (Test) 4 (Iris) 64 (Digits) 8 (Electricity)\n",
        "// BLOCK_SIZE 128 (others) 64 (Digits)\n",
        "// MAX_BLOCKS 256 (others) 1024 (Luna500K) 20048, 131072\n",
        "#define MAX_POINTS 2048\n",
        "#define NF 2\n",
        "#define BLOCK_SIZE 128\n",
        "\n",
        "#define MAX_CLUSTERS 16\n",
        "#define MAX_BLOCKS 256\n",
        "\n",
        "\n",
        "// Calculate the euclidian distance between two points in the CPU\n",
        "float distance(float v1[], float v2[]) {\n",
        "    float sum = 0.0;\n",
        "    for (int d = 0; d < NF; d++) {\n",
        "        sum += pow((v1[d] - v2[d]), 2);\n",
        "    }\n",
        "    return sqrt(sum);\n",
        "}\n",
        "\n",
        "// Calculate the euclidian distance between two points in the GPU\n",
        "__device__ float distance(float *s_point, int p, int q, int nfeat) {\n",
        "    float sum = 0.0;\n",
        "    for (int d = 0; d < nfeat; d++) {\n",
        "        sum = sum + pow((s_point[p+d] - s_point[q+d]), 2);\n",
        "    }\n",
        "    return sqrt(sum);\n",
        "}\n",
        "\n",
        "// Kernel that calculates the parcial sums (in each dimenstion) of the instances coordenates\n",
        "__global__ void centroids(int cluster, float *d_centroid_tmp, float *d_point, int *d_cluster_start, int nfeat) {\n",
        "\n",
        "  __shared__ float s_centroid[BLOCK_SIZE * NF];\n",
        "  int tid = threadIdx.x;\n",
        "  int lower = d_cluster_start[cluster];\n",
        "  int i = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "  int size = d_cluster_start[cluster+1] - d_cluster_start[cluster];\n",
        "  int p; //reduction step: 64, 32, 16, 8, 4, 2,1\n",
        "\n",
        "  // All threads initialize with zero the shared memory\n",
        "  for (int d = 0; d < nfeat; d++) {\n",
        "    s_centroid[tid * nfeat + d] = 0.0;\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // Copy points from global memory to shared memory\n",
        "  if (i < size) {\n",
        "    for (int d = 0; d < nfeat; d++) {\n",
        "      s_centroid[tid * nfeat + d] = (float ) d_point[(lower + i)*nfeat + d];\n",
        "    }\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // Perform a local reduction on the memory shared data\n",
        "  // It starts with 64 threads, then 32, 16, 8, 4, 2, 1\n",
        "  p = blockDim.x / 2;\n",
        "  while (p != 0) {\n",
        "    if (tid < p) {\n",
        "\t    for (int d = 0; d < nfeat; d++) {\n",
        "        s_centroid[tid*nfeat+d] = s_centroid[tid*nfeat+d] + s_centroid[(tid+p)*nfeat+d];\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "    p = p/2;\n",
        "  }\n",
        "\n",
        "  // Thread zero of each block moves the local result to the global memory\n",
        "  if (tid == 0) {\n",
        "    for (int d = 0; d < nfeat; d++) {\n",
        "        d_centroid_tmp[blockIdx.x * nfeat + d] = (float )s_centroid[d];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// Kernel that finds the cluster/point with the greatest distance from the centroid\n",
        "__global__ void maxs_intra(int cluster, int *d_index_tmp, float *d_maxs_tmp, float *d_centroid, float *d_point, int *d_cluster_start, int nfeat) {\n",
        "\n",
        "  __shared__ float s_point[(BLOCK_SIZE+1)*NF];\n",
        "  __shared__ int s_pos[(BLOCK_SIZE+1)];\n",
        "  int tid = threadIdx.x;\n",
        "  int lower = d_cluster_start[cluster];\n",
        "  int i = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "  int size = d_cluster_start[cluster+1] - d_cluster_start[cluster];\n",
        "  int nb, d, p, r, q;\n",
        "  float dist;\n",
        "\n",
        "  // All threads initialize shared memory\n",
        "  s_pos[tid] = lower + tid;\n",
        "  for (d = 0; d < nfeat; d++) {\n",
        "    s_point[tid*nfeat+d] = 0.0;\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // Copy data points from global memory to shared memory\n",
        "  if (i < size) {\n",
        "    for (d = 0; d < nfeat; d++) {\n",
        "      s_point[tid*nfeat+d] = d_point[(lower+i)*nfeat+d];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // store centroid in the last position of the vector shared memory to save memory\n",
        "  if (tid == 0) {\n",
        "    for (d = 0; d < nfeat; d++) {\n",
        "      s_point[blockDim.x*nfeat+d] = d_centroid[cluster*nfeat+d];\n",
        "    }\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // adjust limit for the last block\n",
        "  if (blockIdx.x == (gridDim.x -1)) {\n",
        "    nb = size % blockDim.x;\n",
        "  } else {\n",
        "    nb = blockDim.x;\n",
        "  }\n",
        "\n",
        "  // each thread calculates dist\n",
        "  if (tid < nb) {\n",
        "    r = tid*nfeat; // point index\n",
        "    q = blockDim.x*nfeat; // centroid index\n",
        "    dist = distance(s_point, r, q, nfeat);\n",
        "    s_point[tid*nfeat] = dist;\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // reduction to find the maximum distance\n",
        "  p = blockDim.x / 2; // log steps\n",
        "  while (p != 0) {\n",
        "    if (tid < p) {\n",
        "      if (s_point[tid*nfeat] < s_point[(tid+p)*nfeat]) {\n",
        "        s_point[tid*nfeat] = s_point[(tid+p)*nfeat];\n",
        "        s_pos[tid] = s_pos[tid+p];\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "    p = p/2;\n",
        "  }\n",
        "\n",
        "  // Thread zero of each block copy data to glocal memory\n",
        "  if (tid == 0) {\n",
        "    d_index_tmp[blockIdx.x] = s_pos[0];\n",
        "    d_maxs_tmp[blockIdx.x] = s_point[0];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int num_clusters; // number of clusters\n",
        "  int cluster_size[MAX_CLUSTERS]; //cluster sizes\n",
        "  static float point[MAX_POINTS][NF]; // cluster data\n",
        "  float *d_point; // GPU cluster data\n",
        "  float centroid[MAX_CLUSTERS][NF]; // centroid data\n",
        "  float *d_centroid; // GPU centroid data\n",
        "  float centroid_tmp[MAX_BLOCKS][NF]; // centroid temporary data\n",
        "  float centroid_global[NF]; // global centroid\n",
        "  float *d_centroid_tmp; // GPU centroid temporary data\n",
        "  int index_tmp[MAX_BLOCKS]; // index temporary data\n",
        "  int *d_index_tmp; // GPU index temporary data\n",
        "  float maxs_tmp[MAX_BLOCKS]; // max values temporary\n",
        "  float *d_maxs_tmp; // GPU max values temporary\n",
        "  int cluster_start[MAX_CLUSTERS+1]; // start cluster indexes\n",
        "  int *d_cluster_start; // GPU start cluster indexes\n",
        "  FILE *fp; // file pointer\n",
        "  int size = 0; // total number of points\n",
        "  int nfeat; // number of attributes\n",
        "  clock_t start, stop; // measure time\n",
        "  double running_time; // running time\n",
        "  int nblocks; // number of blocks\n",
        "  int cluster; // current cluster\n",
        "  float sum; // sum of elements\n",
        "  float dist, dist1; // distance\n",
        "  float max_distance; // maximum distance\n",
        "  float min_distance, min_distance1; // minimum distance\n",
        "  int cluster1; // cluster chosen\n",
        "  int p1; // index chosen\n",
        "\n",
        "  // Input the number of clusters and the cluster information\n",
        "  // Format: 1st line: #clusters #features, 2nd: cluster sizes, 3rd: data\n",
        "\n",
        "   fp = fopen(\"test_k2_f2_10.dat\", \"r\");\n",
        "  // fp = fopen(\"iris_k3_f4_150.dat\", \"r\");\n",
        "  // fp = fopen(\"digits_k10_f64_1797.dat\", \"r\");\n",
        "  // fp = fopen(\"electricity_k2_f8_45311.dat\", \"r\");\n",
        "  // fp = fopen(\"iris_k3_f4_150.dat\", \"r\");\n",
        "  // fp = fopen(\"digits_k13_f64_1797s.dat\", \"r\");\n",
        "  // fp = fopen(\"luna_k5_f20_500000.dat\", \"r\");\n",
        "  // fp = fopen(\"satimage_k8_f36_6430s.dat\", \"r\");\n",
        "  // fp = fopen(\"aggregation_k9_f2_788s.dat\", \"r\");\n",
        "  // fp = fopen(\"luna_k9_f20_5000s.dat\", \"r\");\n",
        "  // fp = fopen(\"texture_k13_f40_5500s.dat\", \"r\");\n",
        "  //   fp = fopen(\"barcrawl_k10_f3_14057567.dat\", \"r\");\n",
        "\n",
        "  // Read file (upload file first if running in Collab)\n",
        "  fscanf(fp, \"%d %d\", &num_clusters, &nfeat);\n",
        "  for (int k = 0; k < num_clusters; k++) {\n",
        "    fscanf(fp, \"%d\", &cluster_size[k]);\n",
        "    size = size + cluster_size[k];\n",
        "  }\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    for (int j = 0; j < nfeat; j++) {\n",
        "       fscanf(fp, \"%f\", &point[i][j]);\n",
        "    }\n",
        "  }\n",
        "  fclose(fp);\n",
        "\n",
        "  // prefix sum to find out the beginning of each cluster\n",
        "  cluster_start[0] = 0;\n",
        "  for (int i = 1; i < num_clusters+1; i++) {\n",
        "    cluster_start[i] = cluster_start[i-1] + cluster_size[i-1];\n",
        "  }\n",
        "\n",
        "  // initialize global centroid with zero\n",
        "  for (int j = 0; j < nfeat; j++) {\n",
        "    centroid_global[j] = 0.0;\n",
        "  }\n",
        "\n",
        "  // Allocate GPU memory\n",
        "  cudaMalloc(&d_cluster_start, (MAX_CLUSTERS+1)*sizeof(int));\n",
        "  cudaMalloc(&d_point, MAX_POINTS*NF*sizeof(float));\n",
        "  cudaMalloc(&d_centroid_tmp, MAX_BLOCKS*NF*sizeof(float));\n",
        "  cudaMalloc(&d_index_tmp, MAX_BLOCKS*sizeof(int));\n",
        "  cudaMalloc(&d_maxs_tmp, MAX_BLOCKS*sizeof(float));\n",
        "  cudaMalloc(&d_centroid, MAX_CLUSTERS*NF*sizeof(float));\n",
        "\n",
        "  // start clock to measure running time\n",
        "  start = clock();\n",
        "\n",
        "  // Copy data (cluster points and start indices) to the GPU\n",
        "  cudaMemcpy(d_point, point, MAX_POINTS*nfeat*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_cluster_start, cluster_start, (MAX_CLUSTERS+1)*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // find centroids: launch the kernel for each cluster\n",
        "  for (cluster = 0; cluster < num_clusters; cluster++) {\n",
        "\n",
        "    // Number of blocks is size of cluster divided by the block size\n",
        "    nblocks = (cluster_size[cluster] + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    // launch kernel and verify if got any error\n",
        "    centroids<<<nblocks, BLOCK_SIZE>>>( cluster, d_centroid_tmp, d_point, d_cluster_start, nfeat );\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if(error != cudaSuccess) { printf(\"CUDA error: %s\\n\", cudaGetErrorString(error)); exit(-1); }\n",
        "\n",
        "    // Wait for the kernel to finish and copy centroid temporary data for the host (CPU)\n",
        "    // The kernel returns the parcial sums of each block\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemcpy(&centroid_tmp, d_centroid_tmp, MAX_BLOCKS*NF*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Calculate centroid and store it in the centroid_tmp\n",
        "    // The parcial sums need to be accumulated and divided by the cluster size\n",
        "    for (int i = 0; i < nfeat; i++) {\n",
        "      sum = 0.0;\n",
        "      for (int j = 0; j < nblocks; j++) {\n",
        "        sum = sum + centroid_tmp[j][i];\n",
        "      }\n",
        "      centroid_global[i] = centroid_global[i] + sum;\n",
        "      centroid_tmp[0][i] = sum / (float )cluster_size[cluster];\n",
        "      centroid[cluster][i] = centroid_tmp[0][i];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"\\nCentroid Global: \");\n",
        "  for (int i = 0; i < nfeat; i++) {\n",
        "     centroid_global[i] = centroid_global[i] / size;\n",
        "     printf(\"%.2f \", centroid_global[i]);\n",
        "  }\n",
        "\n",
        "  // Copy centroids to the GPU\n",
        "  cudaMemcpy(d_centroid, centroid, MAX_CLUSTERS*NF*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // COPIED - global centroid\n",
        "  // Find the global centroid and store at centroid[MAX_CLUSTERS][NF]\n",
        "  // Initialize global centroid with zero\n",
        "  for (int k = 0; k < nfeat; k++) {\n",
        "    centroid[MAX_CLUSTERS][k] = 0.0;\n",
        "  }\n",
        "  for (int k = 0; k < nfeat; k++) {\n",
        "    for (int i = 0; i < num_clusters; i++) {\n",
        "      centroid[MAX_CLUSTERS][k] = centroid[MAX_CLUSTERS][k] + centroid[i][k];\n",
        "    }\n",
        "  }\n",
        "  for (int k = 0; k < nfeat; k++) {\n",
        "    centroid[MAX_CLUSTERS][k] = centroid[MAX_CLUSTERS][k] / num_clusters;\n",
        "  }\n",
        "\n",
        "  // Find the centroid closer to the global centroid\n",
        "  min_distance = DBL_MAX;\n",
        "  min_distance1 = DBL_MAX;\n",
        "  for (int i = 0; i < num_clusters; i++) {\n",
        "    for (int k = 0; k < nfeat; k++) {\n",
        "      dist = distance(centroid[i], centroid[MAX_CLUSTERS]);\n",
        "      dist1 = distance(centroid[i], centroid_global);\n",
        "      if (dist < min_distance) {\n",
        "        min_distance = dist;\n",
        "      }\n",
        "      if (dist1 < min_distance1) {\n",
        "        min_distance1 = dist1;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  // Now min_distance is the numerator of the Dunn index\n",
        "  // Now min_distance1 is the numerator of the Dunn index\n",
        "\n",
        "  // Now, find maximum diameter launching the kernel for each cluster again\n",
        "  max_distance = 0;\n",
        "  for (cluster = 0; cluster < num_clusters; cluster++) {\n",
        "\n",
        "    // Number of blocks is size of cluster divided by the block size\n",
        "    nblocks = (cluster_size[cluster] + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    // launch kernel and verify if got any error\n",
        "    maxs_intra<<<nblocks, BLOCK_SIZE>>>( cluster, d_index_tmp, d_maxs_tmp, d_centroid, d_point, d_cluster_start, nfeat );\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if(error != cudaSuccess) { printf(\"CUDA error: %s\\n\", cudaGetErrorString(error)); exit(-1); }\n",
        "\n",
        "    // Wait for the kernel to finish and copy maximum temporary data for the host (CPU)\n",
        "    // The kernel returns the several maximums, one for each block\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemcpy(&maxs_tmp, d_maxs_tmp, MAX_BLOCKS*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(&index_tmp, d_index_tmp, MAX_BLOCKS*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Calculate the global maximum and store it in the max_distance\n",
        "    // The parcial maximums need to be compared and the global maximum stored\n",
        "    // The cluster and the maximum point position need to be saved (cluster1 and p1)\n",
        "    for (int j = 0; j < nblocks; j++) {\n",
        "      if (maxs_tmp[j] > max_distance) {\n",
        "        max_distance = maxs_tmp[j];\n",
        "        p1 = index_tmp[j];\n",
        "        cluster1 = cluster;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // Now that we know the cluster (cluster1) with the point (p1) furthest to the\n",
        "  // centroid, we can calculate de diameter as the maximum distance between p1\n",
        "  // and another point in the same cluster\n",
        "\n",
        "  // store p1 in the first position of centroid, to re-use space, and move it to the GPU\n",
        "  for (int d = 0; d < nfeat; d++) {\n",
        "    centroid[0][d] = point[p1][d];\n",
        "  }\n",
        "  cudaMemcpy(d_centroid, centroid, MAX_CLUSTERS*NF*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Find maximum diameter in the right cluster (cluster1)\n",
        "  // The point p1 is compared to all points of cluster1\n",
        "  // This is done lauching the max_intra kernel once more\n",
        "  cluster = cluster1;\n",
        "  nblocks = (cluster_size[cluster] + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "  maxs_intra<<<nblocks, BLOCK_SIZE>>>( cluster, d_index_tmp, d_maxs_tmp, d_centroid, d_point, d_cluster_start, nfeat );\n",
        "  cudaError_t error = cudaGetLastError();\n",
        "  if(error != cudaSuccess)  { printf(\"CUDA error: %s\\n\", cudaGetErrorString(error)); exit(-1); }\n",
        "\n",
        "  // Wait for the kernel to finish and copy maximum temporary data for the host (CPU)\n",
        "  // The kernel returns the several maximums, one for each block\n",
        "  cudaDeviceSynchronize();\n",
        "  cudaMemcpy(&maxs_tmp, d_maxs_tmp, MAX_BLOCKS*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(&index_tmp, d_index_tmp, MAX_BLOCKS*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Find out the maximum distance (one per block)\n",
        "  // This is the denominator of the Dunn index\n",
        "  max_distance = 0;\n",
        "  for (int j = 0; j < nblocks; j++) {\n",
        "    if (maxs_tmp[j] > max_distance) {\n",
        "      max_distance = maxs_tmp[j];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // finalize runtime calculation\n",
        "  stop = clock();\n",
        "\n",
        "  // Print results\n",
        "  printf(\"\\nMin intercluster %.2f\", min_distance);\n",
        "  printf(\"\\nMin1 intercluster %.2f\", min_distance1);\n",
        "  printf(\"\\nMax intracluster %.2f\", max_distance);\n",
        "  printf(\"\\nThe Dunn index: %.4f\", min_distance / max_distance);\n",
        "  printf(\"\\nThe Dunn index1: %.4f\", min_distance1 / max_distance);\n",
        "\n",
        "  // Print the time taken\n",
        "  running_time = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "  printf(\"\\nTime taken: %lf milissegundos\\n\", 1000.0*running_time);\n",
        "\n",
        "  // Free GPU memory\n",
        "  cudaFree( d_cluster_start );\n",
        "  cudaFree( d_point );\n",
        "  cudaFree( d_centroid_tmp );\n",
        "  cudaFree( d_index_tmp );\n",
        "  cudaFree( d_maxs_tmp );\n",
        "  cudaFree( d_centroid );\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}